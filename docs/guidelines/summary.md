## Summary

We looked at five ‘checklists’ designed to support data scientists in embedding ethics in their work. Three of them, we felt, could be useful to data scientists in specific roles and at particular points in their work. The [DEON Ethics Checklist](https://deon.drivendata.org/), a Python package that includes a checklist of questions for data scientists to ask as part of their development process, could be useful as part of an existing project, particularly because it can be customised for different projects. We liked the Oxford Internet Institute’s [Algorithmic Equity Toolkit](https://www.aclu-wa.org/AEKit), for its focus on explaining ethical concerns and issues to non-technical audiences. And we thought that Digital Catapult’s [Machine Intelligence Ethics Framework](https://www.migarage.ai/ethics-framework/) provided the best overall structure for examining potential ethical problems, particularly because it explains clearly why its extensive structural questions are important and why they need answering.

Two further checklists were less useful, although we did feel that they had their purposes. [A Guide to Writing the NeurIPS Impact Statement](https://medium.com/@operations_18894/a-guide-to-writing-the-neurips-impact-statement-4293b723f832) does what it claims, providing guidance for submitting to a specific technical computer science conference that now requires an ethical impact statement: we felt that this was a very basic guide, but useful to computer scientists who are thinking about the impact of their work outside the academy for the first time. At the other end of the scale, the [EU Ethics Guidelines](https://ec.europa.eu/digital-single-market/en/news/draft-ethics-guidelines-trustworthy-ai) are targeted at national or governmental-scale projects: they may not be useful to individual data scientists or project teams.

Overall, however, the nature of checklists is limited by the fact that they are inherently ‘one-and-done’ tools, while ethics should be embedded in the process as a whole, and ethical evaluation should be iterative. Checklists are also inherently better at spotting gaps and/or problems than identifying solutions. While some of the tools we evaluated could be useful to specific audiences, none can act as a stand-alone tool: they will need to be embedded into a holistic approach, and supplemented by domain-specific expertise with clear calls to positive action, not just avoiding problems.
