# Priorities in an “ideal” toolkit

## Fairness

There should be a balance between **comprehensiveness** and **usability** / interpretability.  
A tool should be adaptable to **context-specific use cases**, and usable in real-life scenarios.  
The tool's UI should provide the user with an **easy flow & examples** (case studies) of what to look for.  
Tools should be **easy to integrate** and technical packages accessible.  
Tools should use a **variety of fairness metrics**, with clearly explained differences and use cases ("what to use where and why").  
The user should be led to understand **different mitigation techniques** and their pros & cons.  

## Explanation

There should be an **"explanability layer"** on top of existing tools used, i.e. for both SciKit, Tensorflow (the closest is [seldon.io Alibi 0.4.0](https://docs.seldon.io/projects/alibi/en/latest/)).  

Explainability needs to be provided to **both technical and business owners**. Data scientists can "translate" technical aspects of the work to non-technical parties, but we also need a wider schematic language to ensure transparency, and to establish the existence of an ethics "frame of mind" across the business.

## Natural Language Processing (NLP)

NLP toolkits should produce bias scores in a standardised way.  
Debiassing should be offered with different techniques.  
Tools should be agnostic to the users' modeling framework.  
They should explain predictions with different techniques.  

## Guidelines / checklists

Guidelines should be **comprehensive** and need to have been stress-tested.  
Tools should provide clear **calls to action**, and a clear 'what next' plan to ensure it can be succesfully integrated in a wider process.  
Tools should support an iterative proces rather than ‘one-and-done’ approach.  

## Communicating ethics

Communicating ethics should be engaging, and have a very **low barrier to entry**: this by definition *needs* to be as accessible as possible. **complex and nuanced** field, without a single source of truth; tools should discuss those nuances and engage the user in a critical approach, for instance questioning the commonly held narratives around AI Ethics.
