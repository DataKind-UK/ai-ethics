# Key takeaways

**Fairness**

- Gap between real-life considerations and the academic vacuum use cases
  - Need examples closer to real-life use cases
  - All products require protected features as input
- Gap between lack of education among practitioners on what is essential in fairness evaluation vs. assumed expertise by tools
- Lack of consistency in methodology - wildly different tools, approaches, techniques
- Lack of tool tackling the end-to-end fairness
- Lack of regression implementation vs. academic theory

**Explanation**

- Tools are often broken and unmaintained
- Explainability needs to be built in and become core of existing libraries - less separation. This is when it gets taken more seriously and we look to democratize AI.
- Difference between tools vrs. Usability - mirrors OS and Commercialized products

**Natural Language Processing (NLP)**

- Lack of NLP-focused package or library with decent documentation around detecting and removing bias that is model agnostic
- Open source tools not robust or standardised or well-documented

**Guidelines / checklists**

- Ethics needs to be an iterative process, and a lot of them are one-off
- Limited calls to action / clarity

**Communicating ethics**

- Existing tools are focused on the US
- The tools we looked at required some familiarity with machine learning models and might be intimidating for complete newcomers
- The tools we examined were useful, but would need to be complemented with other materials in order to persuade audiences that ethics is a necessary part of development and needs to be embedded throughout a product lifecycle
