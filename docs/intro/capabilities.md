# Open-source toolkit current capabilities

## Fairness

- Test against standard set of fairness metrics
- Pick the most “similar” cases to compare predictions
- Experiment with decision thresholds
- Explanations, e.g. feature importance
- Visualizations, distributions, binning / faceting
- Augment model-building process with fairness in mind (e.g. de-biasing or constraint during training)

## Explanation

- Provide explanations for data models as a trial, to evolve and improve data collection, cleaning etc.
- Leads the way in change and explainable AI, just very challenging to maintain
- Commercialization adds to user-friendliness,but lacks in innovation
- Innovation happens in OS predominantly

## Natural Language Processing (NLP)

- Debias static and context dependent embeddings
- Calculate Word Embedding Association Test (WEAT) and possibly other bias scores
- Explain predictions of a model
