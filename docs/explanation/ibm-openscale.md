## [IBM OpenScale](https://www.ibm.com/watson/explainable-ai?mhsrc=ibmsearch_a&mhq=explainable%20ai)

**Description of the tool**

[https://www.ibm.com/cloud/watson-openscale](https://www.ibm.com/cloud/watson-openscale)

**What is its purpose?**

IBM launched this tool in 2018, in an effort to “break open the ‘black box’ at the heart” of AI models. It aims to simplify AI processes, including detailing how recommendations are made, bias detection, and bias mitigation to ensure that fair models are produced, in particular:

1. Measure and track AI outcomes - Track performance of production AI and its impact on business goals, with actionable metrics, in a single console.
2. Tune your AI for business - Apply business results to create a continuous feedback loop that improves and sustains AI outcomes.
3. Govern and explain AI - Maintain regulatory compliance by tracing and explaining AI decisions across workflows, and intelligently detect and correct bias to improve outcomes.

**Who is the intended user?**

It is intended for any model built and used on any platform. Watson OpenScale is available in[ IBM Cloud Pak™ for Data](https://www.ibm.com/products/cloud-pak-for-data) and on[ IBM Cloud™](https://cloud.ibm.com/registration?target=/catalog/services/watson-openscale)

**What is its scope (algorithms, data, types of challenges)?**

It supports regressions and clustering algorithms, and get work with binary and multiclass variables. However, there are some drawbacks such as predictions can only be applied to string or integer data types. It is noted that IBM is actively updating their software though.

**Best for:**

What should practitioners use this tool for? Are there any scenarios / use cases in which this tool is particularly helpful vs. useless?

There is a strong emphasis on how it supports model compliance with regards to business needs and regulatory compliance. For example, IBM OpenScale supports an automated report to be generated for the model, to be submitted to regulators. Specific examples highlighted on their website include:

1. Credit risk modeling
2. Explainable claims processing
3. Predict CSP asset failures

## Pros & cons

**What are the benefits of this tool?**

The key benefit is that this tool is compatible with models and data running virtually anywhere, and is able to assess a model’s explainability and fairness in production. This allows a charity, to link up with IBM OpenScale quite easily to their existing models.

The tool is also built to be user-friendly, in particular for junior data scientists or business product owners who are able to monitor key metrics of their model easily on a dashboard. Graphs are also clearly laid out and there are often layman descriptions of the tests performed.

**What are the challenges in using this tool? **

The main challenge is the costs involved, especially for a charity who might not have the resources to purchase this, instead of using open source tools.

**Case study demo with screenshots**

Dashboard of metrics on models in production. This cover KPIs that can be monitored regularly.

<p id="gdcalert19" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to _media/image19.png). Store image on your image server and adjust path/filename/extension if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert20">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>

![alt_text](_media/image19.png "image_tooltip")

Screenshot outlining how a model is explained by their variables. There are buttons everywhere that can give descriptions to non technical audiences.

<p id="gdcalert20" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to _media/image20.png). Store image on your image server and adjust path/filename/extension if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert21">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>

![alt_text](_media/image20.png "image_tooltip")
